{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnabalajiwork/Sentiment-Analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/bts_2021_1.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Show initial data and check missing values\n",
        "print(data.head())\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Drop rows with missing comment_text\n",
        "data = data.dropna(subset=['comment_text'])\n",
        "\n",
        "# Function to calculate polarity and subjectivity\n",
        "def get_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
        "\n",
        "# Apply sentiment calculation\n",
        "data[['polarity', 'subjectivity']] = data['comment_text'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
        "\n",
        "# Categorize sentiment based on polarity\n",
        "def categorize_sentiment(polarity):\n",
        "    if polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif polarity == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Negative'\n",
        "\n",
        "data['sentiment'] = data['polarity'].apply(categorize_sentiment)\n",
        "\n",
        "# Encode sentiment labels\n",
        "le = LabelEncoder()\n",
        "data['sentiment_encoded'] = le.fit_transform(data['sentiment'])\n",
        "\n",
        "# Vectorize comment_text\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(data['comment_text'])\n",
        "\n",
        "# Target variable\n",
        "y = data['sentiment_encoded']\n",
        "\n",
        "# Split into train and test sets (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = log_reg.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Function to predict sentiment, polarity, and subjectivity for new comments\n",
        "def predict_sentiment_with_polarity_subjectivity(new_comments):\n",
        "    new_comments_vectorized = vectorizer.transform(new_comments)\n",
        "    predictions_encoded = log_reg.predict(new_comments_vectorized)\n",
        "    predicted_sentiments = le.inverse_transform(predictions_encoded)\n",
        "    polarity_subjectivity = [get_sentiment(comment) for comment in new_comments]\n",
        "\n",
        "    results = []\n",
        "    for comment, sentiment, (polarity, subjectivity) in zip(new_comments, predicted_sentiments, polarity_subjectivity):\n",
        "        results.append({\n",
        "            'Comment': comment,\n",
        "            'Predicted Sentiment': sentiment,\n",
        "            'Polarity': polarity,\n",
        "            'Subjectivity': subjectivity\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "# Test new comments\n",
        "new_comments = [\n",
        "    \"I love you\",\n",
        "    \"I didn't like this video at all, but it wasn't a waste of time\",\n",
        "    \"I hate you\"\n",
        "]\n",
        "\n",
        "predicted_results = predict_sentiment_with_polarity_subjectivity(new_comments)\n",
        "\n",
        "for result in predicted_results:\n",
        "    print(f\"Comment: '{result['Comment']}'\")\n",
        "    print(f\"Predicted Sentiment: {result['Predicted Sentiment']}\")\n",
        "    print(f\"Polarity: {result['Polarity']}\")\n",
        "    print(f\"Subjectivity: {result['Subjectivity']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rjegxHlgFhy",
        "outputId": "a067ea20-d895-4928-af66-bcab373588f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  query                                          url  \\\n",
            "0   bts  https://www.youtube.com/watch?v=S8GpX3SAeig   \n",
            "1   bts  https://www.youtube.com/watch?v=S8GpX3SAeig   \n",
            "2   bts  https://www.youtube.com/watch?v=S8GpX3SAeig   \n",
            "3   bts  https://www.youtube.com/watch?v=S8GpX3SAeig   \n",
            "4   bts  https://www.youtube.com/watch?v=S8GpX3SAeig   \n",
            "\n",
            "                                               title           upload_date  \\\n",
            "0  5 Hour BTS Piano Playlist | Study & Relax with...  2021-01-01T10:58:00Z   \n",
            "1  5 Hour BTS Piano Playlist | Study & Relax with...  2021-01-01T10:58:00Z   \n",
            "2  5 Hour BTS Piano Playlist | Study & Relax with...  2021-01-01T10:58:00Z   \n",
            "3  5 Hour BTS Piano Playlist | Study & Relax with...  2021-01-01T10:58:00Z   \n",
            "4  5 Hour BTS Piano Playlist | Study & Relax with...  2021-01-01T10:58:00Z   \n",
            "\n",
            "    channel    views   likes  dislikes  comment_count  \\\n",
            "0  DooPiano  2444982  119269       501           3224   \n",
            "1  DooPiano  2444982  119269       501           3224   \n",
            "2  DooPiano  2444982  119269       501           3224   \n",
            "3  DooPiano  2444982  119269       501           3224   \n",
            "4  DooPiano  2444982  119269       501           3224   \n",
            "\n",
            "                                        comment_text          comment_author  \\\n",
            "0  ♪ Listen on Spotify!: https://spoti.fi/3gC9GfA...                DooPiano   \n",
            "1  My ears: *relaxing* My hands: *writing*  My le...             •ɱĭss süğą•   \n",
            "2  Parents: You have to make us proud  Partner: Y...  Leian Xyrielle Dayahan   \n",
            "3  Little boy: “Are you an angel?”  Girl: “What?”...                   Lisha   \n",
            "4  Reasons to live:    “Suicide doesn’t stop the ...               Grace Cho   \n",
            "\n",
            "           comment_date  comment_likes  \n",
            "0  2021-01-01T10:58:20Z           3884  \n",
            "1  2021-01-29T15:42:43Z           4077  \n",
            "2  2021-03-09T00:52:35Z            827  \n",
            "3  2021-02-12T15:48:08Z            921  \n",
            "4  2021-02-02T18:39:00Z           2248  \n",
            "query             0\n",
            "url               0\n",
            "title             0\n",
            "upload_date       0\n",
            "channel           0\n",
            "views             0\n",
            "likes             0\n",
            "dislikes          0\n",
            "comment_count     0\n",
            "comment_text      0\n",
            "comment_author    0\n",
            "comment_date      0\n",
            "comment_likes     0\n",
            "dtype: int64\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.81      0.56      0.66       443\n",
            "     Neutral       0.88      0.94      0.91      2722\n",
            "    Positive       0.90      0.88      0.89      2494\n",
            "\n",
            "    accuracy                           0.88      5659\n",
            "   macro avg       0.86      0.79      0.82      5659\n",
            "weighted avg       0.88      0.88      0.88      5659\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 246  106   91]\n",
            " [  19 2550  153]\n",
            " [  38  257 2199]]\n",
            "Comment: 'I love you'\n",
            "Predicted Sentiment: Positive\n",
            "Polarity: 0.5\n",
            "Subjectivity: 0.6\n",
            "\n",
            "Comment: 'I didn't like this video at all, but it wasn't a waste of time'\n",
            "Predicted Sentiment: Neutral\n",
            "Polarity: -0.2\n",
            "Subjectivity: 0.0\n",
            "\n",
            "Comment: 'I hate you'\n",
            "Predicted Sentiment: Negative\n",
            "Polarity: -0.8\n",
            "Subjectivity: 0.9\n",
            "\n"
          ]
        }
      ]
    }
  ]
}